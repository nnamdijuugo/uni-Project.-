{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">SIT 720 - Machine Learning</span>\n",
    "\n",
    "---\n",
    "Lecturer:   Chandan Karmakar     | karmakar@deakin.edu.au<br />\n",
    "\n",
    "\n",
    "School of Information Technology, <br />\n",
    "Deakin University, VIC 3125, Australia.\n",
    "\n",
    "---\n",
    "\n",
    "## Assignment 4\n",
    "\n",
    "\n",
    "In this assignment, you will use a lot of concepts learnt in this unit to come up with a good solution for a given human activity recognition problem.\n",
    "\n",
    "**Instructions**\n",
    "1. The dataset consists of training and testing data in \"train\" and \"test\" folders. Use training data: X_train.txt labels: y_train.txt and testing data: X_test.txt   labels: y_test.txt. There are other files that also come with the dataset and may be useful in understanding the dataset better.\n",
    "\n",
    "2. Please read the pdf file \"dataset-paper.pdf\" to answer Part 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Understanding the data **(2 Marks)**\n",
    "\n",
    "Answer the following questions briefly, after reading the paper "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the objective of the data collection process? **(0.5 Marks)**\n",
    "\n",
    "\n",
    "\n",
    "* What human activity types does this dataset have? How many subjects/people have performed these activities? **(0.5 Marks)** \n",
    "\n",
    "\n",
    "\n",
    "* How many instances are available in the training and test sets? How many features are used to represent each instance? Summarize the type of features extracted in 2-3 sentences. **(0.5 Marks)**\n",
    "\n",
    "\n",
    "\n",
    "* Describe briefly what machine learning model is used in this paper for activity recognition and how is it trained. How much is the maximum accuracy achieved? **(0.5 Marks)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: K-Nearest Neighbour Classification **(5 Marks)**\n",
    "\n",
    "Build a K-Nearest Neighbor classifier for this data.  \n",
    "\n",
    "- Let K take values from 1 to 50. Show a plot of cross-validation accuracy with respect to K. **(1 Mark) ** \n",
    "- Choose the best value of K based on model performance P. **(2 Marks) **\n",
    "- Using the best K value, evaluate the model performance on the supplied test set. Report the confusion matrix, multi-class averaged F1-score and accuracy. **(2 Marks)**\n",
    "\n",
    "*[Hints: To choose the best K value, you have to do the following:*\n",
    "- *For each value of K, use 10 fold cross-validation to computer the performance P. *\n",
    "- *The best hyperparameter will be the one that gives maximum validation performance.*\n",
    "- *Performance is defined as: P='f1-score' if fID=0, P='accuracy' if fID=1. Calculate fID using modulus operation fID=SID % 2, where SID is your student ID. For example, if your student ID is 356289 then fID=(356289 % 2)=1 then use 'accuracy' for selecting the best value of K.]* <br />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Multiclass Logistic Regression with Elastic Net **(5 Marks)**\n",
    "\n",
    "Build an elastic-net regularized logistic regression classifier for this data. \n",
    "\n",
    "- Elastic-net regularizer takes in 2 parameters: alpha and l1-ratio. Use the following values for alpha: 1e-4,3e-4,1e-3,3e-3, 1e-2,3e-2. Use the following values for l1-ratio: 0,0.15,0.5,0.7,1. Choose the best values of alpha and l1-ratio based on model performance P. ** (2 Marks)**\n",
    "\n",
    "- Draw a surface plot of F1-score with respect to alpha and l1-ratio values. ** (1 Mark)**\n",
    "\n",
    "- Use the best value of alpha and l1-ratio to re-train the model on the training set and use it to predict the labels of the test set. Report the confusion matrix, multi-class averaged F1-score and accuracy. ** (1+1=2 Marks)**\n",
    "\n",
    "*[Hints: To choose the best alpha/l1-ratio value, you have to do the following:*\n",
    "- *For each value of hyperparameter, use 10 fold cross-validation to computer the performance P.* \n",
    "- *The best hyperparameter will be the one that gives maximum validation performance.*\n",
    "- *Performance is defined as: P='accuracy' if fID=0, P='f1-score' if fID=1. Calculate fID using modulus operation fID=SID % 2, where SID is your student ID. For example, if your student ID is 356289 then fID=(356289 % 2)=1 then use 'f1-score' for selecting the best value of alpha/l1-ratio. ]*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Support Vector Machine (RBF Kernel) **(6 Marks)**\n",
    "\n",
    "Build a SVM (with RBF Kernel) classifier for this data. \n",
    "- SVM with RBF takes 2 parameters: gamma (length scale of the RBF kernel)  and C (the cost parameter). Use the following values for gamma: 1e-3, 1e-4. Use the following values for C: 1, 10, 100, 1000. Choose the best values of gamma and C based on model performance P. **(2 Marks)**\n",
    "\n",
    "- Draw a surface plot of F1-score with respect to gamma and C. Describe the graph. **(1+1=2 Mark)**\n",
    "\n",
    "- Use the best value of gamma and C to re-train the model on the training set and use it to predict the labels of the test set. Report the confusion matrix, multi-class averaged F1-score and accuracy. **(1+1=2 Marks)**\n",
    "\n",
    "*[Hints: To choose the best gamma/C value, you have to do the following:*\n",
    "- *For each value of hyperparameter, use 10 fold cross-validation to computer the performance P.* \n",
    "- *The best hyperparameter will be the one that gives maximum validation performance.*\n",
    "- *Performance is defined as: P='f1-score' if fID=0, P='precision' if fID=1, P='accuracy' if fID=2. Calculate fID using modulus operation fID=SID % 3, where SID is your student ID. For example, if your student ID is 356289 then fID=(356289 % 3)=0 then use 'f1-score' for selecting the best value of gamma/C.]*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Random Forest **(6 Marks)**\n",
    "\n",
    "Build a Random forest classifier for this data. \n",
    "- Random forest uses two parameters: the tree-depth for each decision tree and the number of trees. Use the following values for the tree-depth: 300,500,600 and the number of trees: 200,500,700. Choose the best values of tree-depth and number of treesbased on model performance P. **(2 Marks)**\n",
    "\n",
    "- Draw a surface plot of F1-score with respect to tree-depth and number of trees. Describe the graph. **(1+1=2 Marks)**\n",
    "\n",
    "- Use the best value of tree-depth and number of trees to re-train the model on the training set and use it to predict the labels of the test set. Report the confusion matrix, multi-class averaged F1-score and accuracy. **(1+1=2 Marks)**\n",
    "\n",
    "*[Hints: To choose the 'tree-depth'/'number of trees' value, you have to do the following:*\n",
    "- *For each value of hyperparameter, use 10 fold cross-validation to computer the performance P.* \n",
    "- *The best hyperparameter will be the one that gives maximum validation performance.*\n",
    "- *Performance is defined as: P='f1-score' if fID=0, P='precision' if fID=1, P='accuracy' if fID=2, P='recall' if fID=3 . Calculate fID using modulus operation fID=SID % 4, where SID is your student ID. For example, if your student ID is 356289 then fID=(356289 % 4)=1 then use 'precision' for selecting the best value of 'tree-depth'/'number of trees'.]*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6: Discussion **(6 Marks)**\n",
    "\n",
    "- Write a brief discussion about which classification method achieved the best performance and your thoughts on the reason behind this. **(2 Marks)** \n",
    "- Which method performed the worst and why? **(2 Marks)** \n",
    "- Do you have any suggestions to further improve model performances? **(2 Marks)**\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
